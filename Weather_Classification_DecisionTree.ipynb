{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa8b830",
   "metadata": {},
   "source": [
    "# Weather Classification using Decision Trees\n",
    "\n",
    "**Student Assignment Notebook**\n",
    "\n",
    "Follow the steps and run each cell. Ensure the dataset `Weather Data.csv` is uploaded in the same folder as this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d19c5",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cecbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d36069",
   "metadata": {},
   "source": [
    "## 2. Load the dataset\n",
    "Upload `Weather Data.csv` in the notebook folder, then run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (make sure 'Weather Data.csv' is present)\n",
    "fn = 'Weather Data.csv'\n",
    "try:\n",
    "    data = pd.read_csv(fn)\n",
    "    print('Loaded dataset:', fn)\n",
    "    print('Shape:', data.shape)\n",
    "    display(data.head())\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"{fn} not found. Upload 'Weather Data.csv' to the same directory as this notebook and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92ef2a",
   "metadata": {},
   "source": [
    "## 3. Quick Data Inspection and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5334f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(data.info())\n",
    "print('\\nMissing values per column:')\n",
    "print(data.isna().sum())\n",
    "\n",
    "# Drop Date/Time column if present\n",
    "if 'Date/Time' in data.columns:\n",
    "    data.drop(['Date/Time'], axis=1, inplace=True)\n",
    "\n",
    "# Show unique weather categories\n",
    "print('\\nUnique Weather categories (sample):')\n",
    "print(data['Weather'].unique())\n",
    "\n",
    "# Group rare categories into 'Other' for stability\n",
    "top_cats = data['Weather'].value_counts().nlargest(6).index.tolist()\n",
    "print('\\nTop categories to keep:', top_cats)\n",
    "\n",
    "data['Weather'] = data['Weather'].apply(lambda x: x if x in top_cats else 'Other')\n",
    "print('\\nValue counts after grouping:')\n",
    "print(data['Weather'].value_counts())\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "print('\\nAfter dropping NA, shape:', data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942a656",
   "metadata": {},
   "source": [
    "## 4. Feature Preparation\n",
    "Encode categorical features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y\n",
    "X = data.drop(['Weather'], axis=1)\n",
    "y = data['Weather']\n",
    "\n",
    "# Encode categorical columns in X\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print('Classes:', list(le.classes_))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e2a2e",
   "metadata": {},
   "source": [
    "## 5. Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.25, random_state=42, stratify=y_enc)\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f06b28",
   "metadata": {},
   "source": [
    "## 6. Train Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72792ccc",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e956c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt, feature_names=X.columns, class_names=le.classes_, filled=True, rounded=True, max_depth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695c0c6",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(dt.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(fi.head(10))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "fi.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab613e6",
   "metadata": {},
   "source": [
    "## 9. Optional Improvements (suggested)\n",
    "- Hyperparameter tuning with GridSearchCV or RandomizedSearchCV\n",
    "- Cross-validation\n",
    "- Use OneHotEncoder for categorical variables with many levels\n",
    "- Prune tree or limit max_depth to avoid overfitting\n",
    "\n",
    "## 10. Save model (optional)\n",
    "# You can save the trained model using joblib\n",
    "# import joblib\n",
    "# joblib.dump({'model': dt, 'label_encoder': le}, 'weather_dt_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b58125",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Submission instructions:**\n",
    "1. Run each cell in order after uploading `Weather Data.csv`.\n",
    "2. Save the executed notebook and submit the `.ipynb` file to the Student Portal.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
